\section{Testing Machine Learning Programs}
\subsection{Properties of Machine Learning Applications for Use in Metamorphic Testing \cite{Murphy}}
In the absence of a reliable oracle to indicate the correct output for arbitrary inputs, machine learning programs are often very hard to test. The general term for such softwares that do not have a reliable test oracle is “non-testable programs”. Such programs can be tested in one of the two ways:
\begin{itemize}
  \item Creating multiple implementations of the same program and testing them on same inputs and comparing the results. If the outputs are not same then either of the implementations can contain error. This approach is called pseudo-oracle.
  \item In absence of multiple oracle, metamorphic testing can be used. In metamorphic testing, the input is modified using a metamorphic relation such that the two sets of input will generate similar outputs. If similar outputs are not observed then there must be a defect.
\end{itemize}
The main challenge with metamorphic testing is to come up with the metamorphic relations to transform inputs since such coming up with such relations require domain knowledge and/or familiarity with the implementation.
In this paper the authors seek to create a taxonomy of metamorphic relationships that can be applied to the input data for both supervised and unsupervised machine learning softwares. These set of properties can be applied to define the metamorphic relationships so that metamorphic testing can be used as a general testing method for machine learning applications. The problem with some of the current machine learning frameworks like: Weka and Orange is that they compare the quality of results but don’t evaluate the correctness of the results. The authors apply metamorphic testing to three ML applications: MartiRank, SVM-Light, PAYL.
MartiRank is a supervised ML algorithm that applies segmentation and sorting of the input data to create a model. The algorithm then performs similar operations from the model on the test data to produce a ranking list. SVM-Light is an open-source implementation of SVM that also has a ranking mode. The authors also investigated an intrusion detection system called PAYL. PAYL is an unsupervised machine learning system. It’s dataset simply consist of TCP/IP network payloads(stream of bytes) without any label or classification.
Based on the analysis of MartiRank algorithm, the authors realized that the actual values of the attributes were not very important but their relative values determined the model. Thus, adding a constant value to every attribute or multiplying each attribute with a positive number, should not affect the model and generate the same ranking as before. Thus, the metamorphic properties identified were: addition and multiplication. Applying the model on two sets of data, one of which created from the other, either by multiplying a positive number or, adding a constant number, should not change the ranking. Changing the order of examples should not affect the model or ranking since the algorithm sorts the inputs thus, MartiRank also has permutative metamorphic property. Multiplying the data by a negative constant value will create a new sorting order which can easily predicted. The only change to the model will be the sorting direction i.e. the algorithm will change the sorting direction but keep the sorting order intact. Thus, MartiRank also displays an invertive metamorphic property where the output can be predicted by taking the opposite of input. MartiRank also includes inclusive and exclusive metamorphic properties. Knowing the model can help predict the position of any new elements.

\subsection{Application of Metamorphic Testing to Supervised Classifiers \cite{Xie2009}}
Building on the previous paper, the authors explore the metamorphic relations based on expected behavior of given machine learning problems. They present a case study on Weka, a popular machine learning framework, which is also the foundation for computational science tools such as BioWeka in bioinformatics. In this paper the authors explore k-Nearest Neighbors and Naive Bayes classifier algorithms. Previously, they researched on Support Vector Machines.
In this paper the authors seek to identify the metamorphic relations for the two algorithms (kNN and NBC). NBC and kNN both calculates the mean and standard deviation of the input data. Thus, the metamorphic relations identified are:
Permuting the order of input data does not affect the mean or standard deviation.
Multiplying the data with -1 does not affect the standard deviation since, the deviation from the mean will still be the same.
Multiplying the data with some other positive number will increase the standard deviation by the same amount. Thus, the output will still be predictable.
The authors then, define the metamorphic relations that a classification algorithm is expected to exhibit:
\begin{enumerate}
  \item Consistency with affine transformation.
  \item Permutation of class labels.
  \item Permutation of attributes.
  \item Addition of uninformative/informative attributes.
  \item Consistency with re-prediction.
  \item Addition of training samples.
  \item Addition of classes by duplicating/re-labeling samples.
  \item Removal of classes/samples.
\end{enumerate}
Next, the authors introduce the notion of validation and verification. Validation refers to choosing the most appropriate algorithm to solve a problem. Verification refers to whether the implemented algorithm is correct or not. Current, software testing methods have not addressed the problem of validation and only focus on verification.
The authors then performed an experiment to verify the correctness of Weka. They created a set of random input data and used the above metamorphic relationships to generate another set of inputs. Upon running the inputs on both the algorithms they realized only a subset of MRs were a necessary property of the corresponding algorithm. It was observed that several MRs violated NBC algorithms. Violations in the MRs that are necessary properties imply defects in implementation. In the case of kNN algorithm, none of the necessary MRs were violated which means that there are no implementation error as per the testing.

\subsection{Dataset Coverage for Testing Machine Learning Computer Programs \cite{Nakajima2016}}
Recently, computer programs for Big Data analytics or statistical machine learning have become essential components of intelligent software systems. Test oracles are rarely available for them, and this unavailability of test oracles is known as the oracle problem. Machine learning programs are  a typical instance of non-testable programs, and is of the known unknowns type. Metamorphic testing (MT) is a method for tackling the oracle problem. Metamorphic relations (MR) play a role as pseudo oracles to check whether executions of the same program differ for two different test inputs. The test inputs are related by translation functions derived from metamorphic properties so that the relationship between the two results is predictable. If the results coincide with each other, the program behavior is relatively correct.
This paper studies the characteristics of the SUT, the supervised learning classifiers.
Identifying Quasi-testable Core: A program component, function or procedure, is quasi-testable if we have appropriate pseudo oracles or metamorphic relations. The result of the program execution embodies uncertainty, because the output is accompanied with the statistical classification performance. The classifier itself is non-testable. However, pseudo oracles with a MT can be used for testing.
Dataset Coverage: Test coverage is essential in software testing because it is a basis to measure how much of the SUT is checked with a set of the input test data. The graph coverage is the most popular model for software testing, because it captures the structural characteristics of software artifacts, such as control-flows or data-flows of a computer program. The paper introduces the notion of dataset coverage to focus on the characteristics of the population distribution in the training dataset. However, complete coverage is not possible. The number of possible populations in datasets is also infinite.
SVM: A support vector machine (SVM)  is a supervised machine learning classifier. The support vectors lie on the dotted hyperplanes parallel to the separating hyperplane. The margin, the minimum gap between the support hyperplane and the separating hyperplane, is chosen to be maximum. The pseudo code is a common, abstract description of implemented SMO computer programs. Because SMO is an algorithm for solving the SVM optimization problem, it corresponds to the model constructor and is an abstract version of the quasi-testable core.

Testing SVMs
Main tasks:
\begin{itemize}
  \item Obtain pseudo oracles.
  \begin{itemize}
    \item MR for Pseudo Oracles: Various combinations of dataset is obtained by reordering the dataset.
    \item MR for Dataset Generation: Dataset is increased to increase the population of the input dataset.
  \end{itemize}
  \item Generate data points that achieve the required dataset coverage: In order that the result is predictable, the population distribution of the initial dataset is simple enough to contain linearly separable data points. Then a series of tests with pseudo oracles that are obtained based on appropriate metamorphic properties is conducted. Then dataset is extended by adding new data points to calculate a new hyperplane.
\end{itemize}
Similar metamorphic testing approach can be applied to K-nearest neighbors and a naive Bayes classifiers. Since testing the whole program at once is not always possible choosing a right SUT from a non-testable program has a large impact on testing activities.
