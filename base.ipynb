{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-1-fb9179979186>:5: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.12.0-py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.12.0-py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.12.0-py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /util/opt/anaconda/deployed-conda-envs/packages/tensorflow/envs/tensorflow-1.12.0-py36/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import MNIST data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"data/\", one_hot=False)\n",
    "\n",
    "import os\n",
    "import enum\n",
    "import logging\n",
    "import shutil, sys                                                                                                                                                    \n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from keras.datasets import mnist as mn\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "K.set_image_dim_ordering('th')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Training Parameters\n",
    "learning_rate = 0.01\n",
    "num_steps = 500\n",
    "batch_size = 128\n",
    "n_images = 5000\n",
    "\n",
    "# Network Parameters\n",
    "n_hidden_1 = 256 # 1st layer number of neurons\n",
    "n_hidden_2 = 256 # 2nd layer number of neurons\n",
    "num_input = 784 # MNIST data input (img shape: 28*28)\n",
    "num_classes = 10 # MNIST total classes (0-9 digits)\n",
    "dropout = 0.25 # Dropout, probability to drop a unit\n",
    "\n",
    "# Load the Mnist test data\n",
    "xTest = mnist.test.images[:n_images]\n",
    "yTest = list(mnist.test.labels[:n_images])\n",
    "xTest = xTest.reshape(xTest.shape[0], 1, 28, 28)\n",
    "# # convert from int to float\n",
    "xTest = xTest.astype('float32')\n",
    "xTestBackup = xTest.copy()\n",
    "yTestBackup = yTest.copy()\n",
    "\n",
    "xTrain = mnist.train.images[:10000]\n",
    "yTrain = list(mnist.train.labels[:10000])\n",
    "xTrain = xTrain.reshape(xTrain.shape[0], 1, 28, 28)\n",
    "xTrain = xTrain.astype('float32')\n",
    "xTrainBackup = xTrain.copy()\n",
    "yTrainBackup = yTrain.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Shade = \"Shade\"\n",
    "Rotate = \"Rotate\"\n",
    "Sheer = \"Sheer\"\n",
    "Shift = \"Shift\"\n",
    "\n",
    "Test = \"Test\"\n",
    "Train = \"Train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the neural network\n",
    "def conv_net(x_dict, n_classes, dropout, reuse, is_training):\n",
    "    \n",
    "    # Define a scope for reusing the variables\n",
    "    with tf.variable_scope('ConvNet', reuse=reuse):\n",
    "        # TF Estimator input is a dict, in case of multiple inputs\n",
    "        x = x_dict['images']\n",
    "\n",
    "        # MNIST data input is a 1-D vector of 784 features (28*28 pixels)\n",
    "        # Reshape to match picture format [Height x Width x Channel]\n",
    "        # Tensor input become 4-D: [Batch Size, Height, Width, Channel]\n",
    "        x = tf.reshape(x, shape=[-1, 28, 28, 1])\n",
    "\n",
    "        # Convolution Layer with 32 filters \n",
    "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
    "\n",
    "        # Convolution Layer with 64 filters \n",
    "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
    "\n",
    "        # Flatten the data to a 1-D vector for the fully connected layer\n",
    "        fc1 = tf.contrib.layers.flatten(conv2)\n",
    "\n",
    "        # Fully connected layer (in tf contrib folder for now)\n",
    "        fc1 = tf.layers.dense(fc1, 1024)\n",
    "        # Apply Dropout (if is_training is False, dropout is not applied)\n",
    "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
    "\n",
    "        # Output layer, class prediction\n",
    "        out = tf.layers.dense(fc1, n_classes)\n",
    "\n",
    "    return out\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    # Because Dropout have different behavior at training and prediction time, we\n",
    "    # need to create 2 distinct computation graphs that still share the same weights.\n",
    "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
    "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits_test, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits_test)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "def neural_net(x_dict):\n",
    "    # TF Estimator input is a dict, in case of multiple inputs\n",
    "    x = x_dict['images']\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_1 = tf.layers.dense(x, n_hidden_1)\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    layer_2 = tf.layers.dense(layer_1, n_hidden_2)\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    out_layer = tf.layers.dense(layer_2, num_classes)\n",
    "    return out_layer\n",
    "\n",
    "# Define the model function (following TF Estimator Template)\n",
    "def nn_model_fn(features, labels, mode):\n",
    "    \n",
    "    # Build the neural network\n",
    "    logits = neural_net(features)\n",
    "    \n",
    "    # Predictions\n",
    "    pred_classes = tf.argmax(logits, axis=1)\n",
    "    pred_probas = tf.nn.softmax(logits)\n",
    "    \n",
    "    # If prediction mode, early return\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode, predictions=pred_classes) \n",
    "        \n",
    "    # Define loss and optimizer\n",
    "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=tf.cast(labels, dtype=tf.int32)))\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n",
    "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
    "    \n",
    "    # Evaluate the accuracy of the model\n",
    "    acc_op = tf.metrics.accuracy(labels=labels, predictions=pred_classes)\n",
    "    \n",
    "    # TF Estimators requires to return a EstimatorSpec, that specify\n",
    "    # the different ops for training, evaluating, ...\n",
    "    estim_specs = tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=pred_classes,\n",
    "      loss=loss_op,\n",
    "      train_op=train_op,\n",
    "      eval_metric_ops={'accuracy': acc_op})\n",
    "\n",
    "    return estim_specs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reloadData(dataType):\n",
    "    if dataType == \"Test\": # Reset test data\n",
    "        global xTest\n",
    "        global yTest\n",
    "        xTest[:] = xTestBackup\n",
    "        yTest[:] = yTestBackup\n",
    "    elif dataType == \"Train\": # Reset training data\n",
    "        global xTrain\n",
    "        global yTrain\n",
    "        xTrain[:] = xTrainBackup\n",
    "        yTrain[:] = yTrainBackup\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TestModel(model, xData, yData, shuffle):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': xData}, y= np.array(yData),\n",
    "            batch_size=batch_size, shuffle=shuffle)\n",
    "    accuracy = model.evaluate(input_fn)\n",
    "    # Prepare the input data\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x={'images': xData}, shuffle=shuffle)\n",
    "    # Use the model to predict the images class\n",
    "    preds = list(model.predict(input_fn))\n",
    "    return preds, accuracy['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def TrainModel(model, xTrain, yTrain, shuffle):\n",
    "    input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "            x={'images': xTrain}, y= np.array(yTrain),\n",
    "            batch_size=batch_size, shuffle=shuffle)\n",
    "    # Train the Model\n",
    "    model.train(input_fn, steps=num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Transform( xData, yData, tType, value ):\n",
    "    \n",
    "    n_images = len(xData)\n",
    "    \n",
    "    # tType = 1 for shade\n",
    "    if tType == \"Shade\":\n",
    "        Xnew = [[[[v-value if v-value>0.0 else 0.0 for v in n] for n in x[0]]] for x in xData]\n",
    "        Xnew = np.array(Xnew)\n",
    "        xData[:] = Xnew.astype('float32')\n",
    "        return;\n",
    "        \n",
    "    # tType = 2 for rotation\n",
    "    if tType == \"Rotate\":\n",
    "        datagen = ImageDataGenerator(rotation_range=value)# fit parameters from data\n",
    "                \n",
    "    # tType = 3 for sheer\n",
    "    if tType == \"Sheer\":\n",
    "        datagen = ImageDataGenerator(shear_range=value)# fit parameters from data\n",
    "        \n",
    "    # tType = 3 for shift\n",
    "    if tType == \"Shift\":   \n",
    "        datagen = ImageDataGenerator(width_shift_range=value, height_shift_range=value)\n",
    "        \n",
    "    datagen.fit(xData)\n",
    "    # configure batch size and retrieve one batch of images\n",
    "    for xBatch, yBatch in datagen.flow(xData, yData, batch_size=n_images, shuffle=False):\n",
    "        xData[:] = xBatch\n",
    "        yData[:] = yBatch\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def DisplayData( xTest, yTest ):\n",
    "    for i in range(len(xTest)):\n",
    "        plt.imshow(np.reshape(xTest[i], [28, 28]), cmap='gray')\n",
    "        plt.show()\n",
    "        print (\"Image Label: \", yTest[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def OpenFile(MT):\n",
    "    filename = str(MT)+\".txt\"\n",
    "    fp = open(filename, 'w')\n",
    "    return fp\n",
    "\n",
    "def CloseFile(fp):\n",
    "    fp.close()\n",
    "    \n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.INFO)\n",
    "#Shade = \"Shade\"\n",
    "#Rotate = \"Rotate\"\n",
    "#Sheer = \"Sheer\"\n",
    "#Shift = \"Shift\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ShuffleMT (mode, fp, iteration):\n",
    "    print (\"Reloading training and test data\")\n",
    "    reloadData(Train)\n",
    "    reloadData(Test)\n",
    "    \n",
    "    if (mode==Train):\n",
    "        print (\"Training model\")\n",
    "        TrainModel(xTrain, yTrain, True)\n",
    "        \n",
    "        print (\"Evaluating Model\")\n",
    "        accuracy = EvaluateModel(xTest, yTest, False)\n",
    "          \n",
    "    elif (mode==Test):\n",
    "        print (\"Evaluating Model\")\n",
    "        accuracy = EvaluateModel(xTest, yTest, True)\n",
    "        \n",
    "    elif (mode==\"Both\"):\n",
    "        print (\"Training model\")\n",
    "        TrainModel(xTrain, yTrain, True)       \n",
    "        print (\"Evaluating Model\")\n",
    "        accuracy = EvaluateModel(xTest, yTest, True)\n",
    "\n",
    "    print(\"Iteration: \", iteration, \" Accuracy: \", accuracy)\n",
    "    if (fp):\n",
    "        fp.write(str(iteration)+\"\\t\"+str(accuracy)+\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 1.12 (py36)",
   "language": "python",
   "name": "tensorflow-1.12-py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
